{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from dask import dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../alcohol replase/Scipts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils as utl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_position = [\"Chest\", \"Hand\", \"Head\", \"Hip\", \"Forearm\", \"Shin\", \"Thigh\", \"UpperArm\", \"Waist\"]\n",
    "environment = [\"Building\", \"Home\", \"Office\", \"Street\", \"Transportation\"]\n",
    "posture = [\"Climbing (down)\", \"Climbing (up)\", \"Jumping\", \"Laydown\", \"Running\", \"Sitting\", \"Standing\", \"Walking\"]\n",
    "activity = [\"DeskWork\", \"Eating/Drinking\", \"Housework\", \"Mealpreparation\", \"Movement\", \"PersonalGrooming\", \"Relaxing\", \n",
    "            \"Shopping\", \"Socializing\", \"Sleeping\", \"Sport\", \"Transportation\"]\n",
    "sub_activity = [\"Somethingelse\", \"GotoWork\", \"WatchingTV\", \"TidyingUp\", \"GoHome\", \"atHome\", \"Breakfast\", \"Brunch\", \"CofeeBreak\",\n",
    "               \"Dinner\", \"Lunch\", \"Snack\", \"Cleaning\", \"GoForAWalk\", \"Playing\", \"ListenToMusic\", \"Bar/Disco\", \"CinemaAtHome\",\n",
    "               \"Party\", \"Basketball\", \"Bicycling\", \"Dancing\", \"Gym\", \"Gymnastics\", \"IceHockey\", \"Jogging\", \"Soccer\", \n",
    "               \"Bicycle\", \"Bus\", \"Car\", \"Motorcycle\", \"Scooter\", \"Skateboard\", \"Train\", \"Tram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_position_lower = [str.lower(p) for p in device_position]\n",
    "environment_lower = [str.lower(p) for p in environment]\n",
    "posture_lower = [str.lower(p) for p in posture]\n",
    "activity_lower = [str.lower(p) for p in activity]\n",
    "sub_activity_lower = [str.lower(p) for p in sub_activity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the date time format for the dataset\n",
    "date_time_format = \"%d.%m.%y %H:%M:%S\"\n",
    "date_time_milli_seconds_format = \"%d.%m.%y %H:%M:%S.%f\"\n",
    "\n",
    "acceleration_frequency = 50\n",
    "orientation_frequency = 50\n",
    "\n",
    "sensor_time_position = 1\n",
    "sensor_value_position = [2, 3, 4]\n",
    "sensor_label_environment_position = 5\n",
    "sensor_label_posture_position = 6\n",
    "sensor_label_device_position = 7\n",
    "sensor_label_activity_position = 8\n",
    "\n",
    "sensor_df_columns = ['id', 'attr_time', 'attr_x', 'attr_y', 'attr_z', 'label_environment',\n",
    "       'label_posture', 'label_deviceposition', 'label_activity',\n",
    "       'label_valid']\n",
    "\n",
    "label_day_position = 1\n",
    "label_subject_id_position = 2\n",
    "label_start_time_position = 3\n",
    "label_end_time_position = 4\n",
    "label_position = 5\n",
    "\n",
    "data_folder = \"../dailylog2016_dataset/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_class_dictionary  = {\n",
    "    'Desk Work': 0,\n",
    "    'Eating/Drinking': 1,\n",
    "    'Housework': 2,\n",
    "    'Meal preparation': 3,\n",
    "    'Movement': 4,\n",
    "    'Personal Grooming': 5,\n",
    "    'Shopping': 6,\n",
    "    'Socializing': 7,\n",
    "    'Transportation': 8,\n",
    "    'Sport': 9,\n",
    "    'Relaxing': 10,\n",
    "    'Take Medication': 11,\n",
    "    'Sleeping': 12\n",
    "}\n",
    "\n",
    "posture_class_dictionary = {\n",
    "    \"Climbing (down)\": 0,\n",
    "    \"Climbing (up)\": 1,\n",
    "    \"Running\": 2,\n",
    "    \"Sitting\": 3,\n",
    "    \"Standing\": 4,\n",
    "    \"Walking\": 5\n",
    "}\n",
    "\n",
    "activity_file_path = \"../Processed data/adl_activity_dataset.pickle\"\n",
    "posture_file_path = \"../Processed data/adl_posture_dataset.pickle\"\n",
    "posture_full_file_path = \"../Processed data/adl_posture_dataset_full.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acceleration (50 Hz), Orientation (50 Hz), GPS (every 10 minutes)\n",
    "- Labels: Activity, Device Position, Environment, Posture\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Device Posistion: Chest, Hand, Head, Hip, Forearm, Shin, Thigh, Upper Arm, Waist\n",
    "- Environment: Building, Home, Office, Street, Transportation\n",
    "- Posture: Climbing, Jumping, Lay, Running, Sitting, Standing, Walking\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Activity - Subactivity\n",
    "- Desk Work - N/A\n",
    "- Eating / Drinking - Breakfast, Brunch, Cofee Break, Dinner, Lunch Snack\n",
    "- Housework - Cleaning, Tidying Up\n",
    "- Meal Preparation - N/A\n",
    "- Movement - Go for a Walk, Go Home, Go to Work\n",
    "- Personal Grooming - N/A\n",
    "- Relaxing - Playing, Listen to Music, Watching TV\n",
    "- Shopping - N/A\n",
    "- Socializing - Bar / Disco, Cinema at Home\n",
    "- Sleeping - N/A\n",
    "- Sport - Basketball, Bicycling, Dancing, Gym, Gymnastics, Ice Hockey, Jogging, Soccer\n",
    "- Transportation - Bicycle, Bus, Car, Motorcycle, Scooter, Skateboard, Train, Tram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window of size 2.56 seconds with 50% overlap i.e., 128 values at 50Hz sampling frequency\n",
    "window_duration = 2.56\n",
    "overlap_percent = 0.5\n",
    "window_length = int(window_duration * acceleration_frequency)\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(total_data, class_):\n",
    "    if len(total_data) < window_length:\n",
    "        return []\n",
    "    \n",
    "    # get the class data\n",
    "    index = np.where(total_data[:, -1] == class_)[0]\n",
    "    class_data = total_data[index, :3]\n",
    "    \n",
    "    # get the X, Y, and Z axis values\n",
    "    class_data_x = class_data[:, 0]\n",
    "    class_data_y = class_data[:, 1]\n",
    "    class_data_z = class_data[:, 2]\n",
    "    \n",
    "    \n",
    "    # now run the windowing methods on each of the axis data\n",
    "    class_segments_x = utl.segment_sensor_reading(class_data_x, window_duration, overlap_percent, acceleration_frequency)\n",
    "    class_segments_y = utl.segment_sensor_reading(class_data_y, window_duration, overlap_percent, acceleration_frequency)\n",
    "    class_segments_z = utl.segment_sensor_reading(class_data_z, window_duration, overlap_percent, acceleration_frequency)\n",
    "    \n",
    "#     print(class_segments_x.shape)\n",
    "#     print(class_segments_y.shape)\n",
    "#     print(class_segments_z.shape)\n",
    "\n",
    "    class_data = np.concatenate([class_segments_x, class_segments_y], axis = 1)\n",
    "    class_data = np.concatenate([class_data, class_segments_z], axis =  1)\n",
    "    class_data = class_data.reshape(-1, window_length, n_channels)\n",
    "    \n",
    "    print(\"Class segments shape {}\".format(class_data.shape))\n",
    "    return class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_samples(x, y, n_samples):\n",
    "    length = len(x)\n",
    "    if length == n_samples:\n",
    "        return x, y\n",
    "    \n",
    "    random_index = np.random.randint(0, length, n_samples)\n",
    "    return x[random_index], y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(x, y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_value = np.min(counts)\n",
    "    \n",
    "    X_ = np.empty((1, window_length, n_channels))\n",
    "    Y_ = np.empty(1)\n",
    "    \n",
    "    for cls in classes:\n",
    "        index = np.where(y == cls)[0]\n",
    "        x_tp = x[index]\n",
    "        y_tp = y[index]\n",
    "        \n",
    "        x_tp, y_tp = select_random_samples(x_tp, y_tp, min_value)\n",
    "        X_ = np.concatenate([X_, x_tp])\n",
    "        Y_ = np.concatenate([Y_, y_tp])\n",
    "        \n",
    "    return X_[1:, ], Y_[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_from_dict(data_dict, label_dict):\n",
    "    X = np.empty((1, window_length, n_channels))\n",
    "    Y = np.empty(1)\n",
    "\n",
    "    for label in label_dict.keys():\n",
    "        segments = np.array(data_dict[label])\n",
    "        print(label, segments.shape)\n",
    "        X = np.concatenate([X, segments])\n",
    "        Y = np.concatenate([Y, np.ones(segments.shape[0], dtype='int') * label_dict[label]])\n",
    "    \n",
    "    return X[1:, ], Y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_indexes = np.array([1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = subject_indexes[random.sample(range(0, max(subject_indexes)), len(subject_indexes)//2)]\n",
    "target_ids = [r for r in subject_indexes if r not in source_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 7, 6]), [2, 3, 4, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_folders(data_folder, label_type, subject_ids=[]):\n",
    "    # container to store the processed data; we have 4 values in each row\n",
    "    processed_data_dict = {}\n",
    "    \n",
    "    # for each subject id\n",
    "    for subject in subject_ids:\n",
    "        # for each subject folder, we have data and image folder\n",
    "        subject_data_folder = data_folder + \"subject\" + str(subject) + \"/\" + \"data/\"\n",
    "            \n",
    "        # now for each extracted acc csv file\n",
    "        try:\n",
    "            csv_files = os.listdir(subject_data_folder + \"acc_csv/\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        for csv_file in csv_files:\n",
    "            clear_output(wait=True)\n",
    "            file_path = subject_data_folder + \"acc_csv/\" + csv_file\n",
    "            print(\"Processing file : \" + file_path)\n",
    "            \n",
    "            # load the CSV file\n",
    "            data_df = pd.read_csv(file_path).to_numpy()#dd.read_csv(file_path).values #\n",
    "            \n",
    "            # get the unique labels in the data\n",
    "            unique_labels = np.unique(data_df[:, label_type])\n",
    "            unique_labels = np.delete(unique_labels, np.where(unique_labels == 'unknown'))\n",
    "            \n",
    "            # for each unique label\n",
    "            for label in unique_labels:\n",
    "                # get the index for this label\n",
    "                indexes = np.where(data_df[:, label_type] == label)[0]\n",
    "\n",
    "                # get the data at the indexes\n",
    "                data_for_label = data_df[indexes]\n",
    "                # get the sensor value 2:5 and the label for the specified type\n",
    "                data_for_label = data_for_label[:, np.r_[2:5, label_type]]\n",
    "                \n",
    "                print(label, data_for_label.shape)\n",
    "                \n",
    "                # convert the sensor values into windows\n",
    "                data_for_label = get_class_data(data_for_label, label)\n",
    "                try:\n",
    "                    processed_data_dict[label].extend(data_for_label)\n",
    "                except:\n",
    "                    processed_data_dict[label] = []\n",
    "                    processed_data_dict[label].extend(data_for_label)\n",
    "                    \n",
    "    return processed_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : ../dailylog2016_dataset/data/subject6/data/acc_csv/SensorAccelerometerData_labeled_day9.csv\n",
      "Climbing (down) (12706, 4)\n",
      "Class segments shape (197, 128, 3)\n",
      "Climbing (up) (3846, 4)\n",
      "Class segments shape (59, 128, 3)\n",
      "Recumbency (332796, 4)\n",
      "Class segments shape (5198, 128, 3)\n",
      "Sitting (1121240, 4)\n",
      "Class segments shape (17518, 128, 3)\n",
      "Standing (398988, 4)\n",
      "Class segments shape (6233, 128, 3)\n",
      "Walking (56987, 4)\n",
      "Class segments shape (889, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "source_dataset = extract_subject_folders(data_folder, sensor_label_posture_position, source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climbing (down) (2144, 128, 3)\n",
      "Climbing (up) (1653, 128, 3)\n",
      "Running (8520, 128, 3)\n",
      "Sitting (525000, 128, 3)\n",
      "Standing (148572, 128, 3)\n",
      "Walking (58461, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "source_x, source_y = get_x_y_from_dict(source_dataset, posture_class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x, source_y = balance_dataset(source_x, source_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_y = np.array(source_y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../Processed data/DL_source_dataset.pickle\", \"wb\")\n",
    "pickle.dump([source_x, source_y, source_ids], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : ../dailylog2016_dataset/data/subject4/data/acc_csv/SensorAccelerometerData_labeled_day9.csv\n",
      "Nicht festgelegt (79058, 4)\n",
      "Class segments shape (1234, 128, 3)\n",
      "gehen (592486, 4)\n",
      "Class segments shape (9256, 128, 3)\n",
      "liegen (1066407, 4)\n",
      "Class segments shape (16661, 128, 3)\n",
      "sitzen (4148886, 4)\n",
      "Class segments shape (64825, 128, 3)\n",
      "springen (106, 4)\n",
      "stehen (1033418, 4)\n",
      "Class segments shape (16146, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "target_dataset = extract_subject_folders(data_folder, sensor_label_posture_position, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climbing (down) (1132, 128, 3)\n",
      "Climbing (up) (1086, 128, 3)\n",
      "Running (1859, 128, 3)\n",
      "Sitting (338832, 128, 3)\n",
      "Standing (99160, 128, 3)\n",
      "Walking (22973, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "target_x, target_y = get_x_y_from_dict(target_dataset, posture_class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x, target_y = balance_dataset(target_x, target_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y = np.array(target_y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../Processed data/DL_target_dataset.pickle\", \"wb\")\n",
    "pickle.dump([target_x, target_y, target_ids], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Extract data from the accelerometer files for the given label type. \n",
    "    @param: data_folder, path to the folder with subjects folder\n",
    "    @param: label_type, which label type to extract from the accelerometer data files. Possible values are \n",
    "        sensor_label_environment_position = 5 for environment labels\n",
    "        sensor_label_posture_position = 6 for posture labels\n",
    "        sensor_label_device_position = 7 for device position labels\n",
    "        sensor_label_activity_position = 8 for activity labels\n",
    "        \n",
    "    @param: open_zips, whether to open the acc_csv zip files or not before extracting the sensor values for the given label type\n",
    "    \n",
    "'''\n",
    "def combine_subject_files(data_folder, label_type, open_zips = False):\n",
    "    # container to store the processed data; we have 4 values in each row\n",
    "    processed_data_dict = {}\n",
    "    \n",
    "    # get the subject folders\n",
    "    subject_folders = os.listdir(data_folder)\n",
    "    \n",
    "    # for each subject folder\n",
    "    for folder in subject_folders:\n",
    "        # for each subject folder, we have data and image folder\n",
    "        subject_data_folder = data_folder + folder + \"/\" + \"data/\"\n",
    "        \n",
    "        # now at this location we have acc_csv zip file. \n",
    "        if open_zips == True:\n",
    "            #open acc_csv zip to get the 14 days data for each subject\n",
    "            zip_file = subject_data_folder + \"acc_csv.zip\"\n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(subject_data_folder + \"acc_csv/\")\n",
    "            except:\n",
    "                # if not able to open the zip file then just continue to next subject\n",
    "                continue\n",
    "            \n",
    "        # now for each extracted acc csv file\n",
    "        try:\n",
    "            csv_files = os.listdir(subject_data_folder + \"acc_csv/\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        for csv_file in csv_files:\n",
    "            clear_output(wait=True)\n",
    "            file_path = subject_data_folder + \"acc_csv/\" + csv_file\n",
    "            print(\"Processing file : \" + file_path)\n",
    "            \n",
    "            # load the CSV file\n",
    "            data_df = pd.read_csv(file_path).to_numpy()#dd.read_csv(file_path).values #\n",
    "            \n",
    "            # get the unique labels in the data\n",
    "            unique_labels = np.unique(data_df[:, label_type])\n",
    "            unique_labels = np.delete(unique_labels, np.where(unique_labels == 'unknown'))\n",
    "            \n",
    "            # for each unique label\n",
    "            for label in unique_labels:\n",
    "                # get the index for this label\n",
    "                indexes = np.where(data_df[:, label_type] == label)[0]\n",
    "\n",
    "                # get the data at the indexes\n",
    "                data_for_label = data_df[indexes]\n",
    "                # get the sensor value 2:5 and the label for the specified type\n",
    "                data_for_label = data_for_label[:, np.r_[2:5, label_type]]\n",
    "                \n",
    "                print(label, data_for_label.shape)\n",
    "                \n",
    "                # convert the sensor values into windows\n",
    "                data_for_label = get_class_data(data_for_label, label)\n",
    "                try:\n",
    "                    processed_data_dict[label].extend(data_for_label)\n",
    "                except:\n",
    "                    processed_data_dict[label] = []\n",
    "                    processed_data_dict[label].extend(data_for_label)\n",
    "                    \n",
    "    return processed_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : ../dailylog2016_dataset/data/subject7/data/acc_csv/SensorAccelerometerData_labeled_day9.csv\n",
      "Nicht festgelegt (609428, 4)\n",
      "Class segments shape (9521, 3, 128)\n",
      "gehen (266100, 4)\n",
      "Class segments shape (4156, 3, 128)\n",
      "klettern/steigen (hoch) (3405, 4)\n",
      "Class segments shape (52, 3, 128)\n",
      "klettern/steigen (runter) (3458, 4)\n",
      "Class segments shape (53, 3, 128)\n",
      "sitzen (1040180, 4)\n",
      "Class segments shape (16251, 3, 128)\n",
      "stehen (19546, 4)\n",
      "Class segments shape (304, 3, 128)\n",
      "Read csv time:  580.0130429267883 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataset = combine_subject_files(data_folder, sensor_label_posture_position)\n",
    "end = time.time()\n",
    "print(\"Read csv time: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climbing (down) (3276, 3, 128)\n",
      "Climbing (up) (2739, 3, 128)\n",
      "Not Specified (98511, 3, 128)\n",
      "Sitting (863832, 3, 128)\n",
      "Standing (247732, 3, 128)\n",
      "Walking (81434, 3, 128)\n",
      "Recumbency (65660, 3, 128)\n",
      "Running (10379, 3, 128)\n",
      "Jumping (4, 3, 128)\n",
      "Nicht festgelegt (80584, 3, 128)\n",
      "gehen (146026, 3, 128)\n",
      "klettern/steigen (hoch) (2110, 3, 128)\n",
      "klettern/steigen (runter) (2857, 3, 128)\n",
      "rennen (7613, 3, 128)\n",
      "sitzen (1023402, 3, 128)\n",
      "stehen (173008, 3, 128)\n",
      "springen (1477, 3, 128)\n",
      "liegen (25977, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset.keys():\n",
    "    print(key, np.array(dataset[key]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climbing (down) (3276, 3, 128)\n",
      "Climbing (up) (2739, 3, 128)\n",
      "Running (10379, 3, 128)\n",
      "Sitting (863832, 3, 128)\n",
      "Standing (247732, 3, 128)\n",
      "Walking (81434, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_x_y_from_dict(dataset, posture_class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1209392, 3, 128), (1209392,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bb2f0d78d4ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposture_full_file_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposture_class_dictionary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = posture_full_file_path\n",
    "f = open(file_path, \"wb\")\n",
    "pickle.dump([X, Y, posture_class_dictionary], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                            Type              Data/Info\n",
      "---------------------------------------------------------------\n",
      "X                                   ndarray           1209392x3x128: 464406528 elems, type `object`, 3715252224 bytes (3543.140625 Mb)\n",
      "Y                                   ndarray           1209392: 1209392 elems, type `float64`, 9675136 bytes (9.2269287109375 Mb)\n",
      "absolute_import                     _Feature          _Feature((2, 5, 0, 'alpha<...>0, 0, 'alpha', 0), 16384)\n",
      "acceleration_frequency              int               50\n",
      "activity                            list              n=12\n",
      "activity_class_dictionary           dict              n=13\n",
      "activity_file_path                  str               ../Processed data/adl_activity_dataset.pickle\n",
      "activity_lower                      list              n=12\n",
      "clear_output                        function          <function clear_output at 0x00000224AD3901F8>\n",
      "combine_subject_files               function          <function combine_subject<...>es at 0x00000224B47B3948>\n",
      "data_folder                         str               ../dailylog2016_dataset/data/\n",
      "dataset                             dict              n=0\n",
      "date_time_format                    str               %d.%m.%y %H:%M:%S\n",
      "date_time_milli_seconds_format      str               %d.%m.%y %H:%M:%S.%f\n",
      "datetime                            module            <module 'datetime' from '<...>onda3\\\\lib\\\\datetime.py'>\n",
      "dd                                  module            <module 'dask.dataframe' <...>\\dataframe\\\\__init__.py'>\n",
      "device_position                     list              n=9\n",
      "device_position_lower               list              n=9\n",
      "division                            _Feature          _Feature((2, 2, 0, 'alpha<...> 0, 0, 'alpha', 0), 8192)\n",
      "end                                 float             1603079327.548638\n",
      "environment                         list              n=5\n",
      "environment_lower                   list              n=5\n",
      "f                                   BufferedWriter    <_io.BufferedWriter name=<...>ure_dataset_full.pickle'>\n",
      "file_path                           str               ../Processed data/adl_posture_dataset_full.pickle\n",
      "get_class_data                      function          <function get_class_data at 0x00000224B47B3B88>\n",
      "get_x_y_from_dict                   function          <function get_x_y_from_di<...>ct at 0x0000022795C88828>\n",
      "key                                 str               liegen\n",
      "label_day_position                  int               1\n",
      "label_end_time_position             int               4\n",
      "label_position                      int               5\n",
      "label_start_time_position           int               3\n",
      "label_subject_id_position           int               2\n",
      "n_channels                          int               3\n",
      "np                                  module            <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "orientation_frequency               int               50\n",
      "os                                  module            <module 'os' from 'C:\\\\Us<...>\\\\Anaconda3\\\\lib\\\\os.py'>\n",
      "overlap_percent                     float             0.5\n",
      "pd                                  module            <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "pickle                              module            <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "plt                                 module            <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "posture                             list              n=8\n",
      "posture_class_dictionary            dict              n=6\n",
      "posture_file_path                   str               ../Processed data/adl_posture_dataset.pickle\n",
      "posture_full_file_path              str               ../Processed data/adl_posture_dataset_full.pickle\n",
      "posture_lower                       list              n=8\n",
      "print_function                      _Feature          _Feature((2, 6, 0, 'alpha<...>0, 0, 'alpha', 0), 65536)\n",
      "select_random_samples               function          <function select_random_s<...>es at 0x00000224B47B39D8>\n",
      "sensor_df_columns                   list              n=10\n",
      "sensor_label_activity_position      int               8\n",
      "sensor_label_device_position        int               7\n",
      "sensor_label_environment_position   int               5\n",
      "sensor_label_posture_position       int               6\n",
      "sensor_time_position                int               1\n",
      "sensor_value_position               list              n=3\n",
      "start                               float             1603078747.5355952\n",
      "sub_activity                        list              n=35\n",
      "sub_activity_lower                  list              n=35\n",
      "sys                                 module            <module 'sys' (built-in)>\n",
      "time                                module            <module 'time' (built-in)>\n",
      "unicode_literals                    _Feature          _Feature((2, 6, 0, 'alpha<...>, 0, 'alpha', 0), 131072)\n",
      "utl                                 module            <module 'Utils' from '../<...>eplase/Scipts\\\\Utils.py'>\n",
      "window_duration                     float             2.56\n",
      "window_length                       int               128\n",
      "zipfile                             module            <module 'zipfile' from 'C<...>conda3\\\\lib\\\\zipfile.py'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
